{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Text Identification OCR - Minimal Version (For Memorization)\n",
        "\n",
        "OpenCV preprocessing + Tesseract OCR + CNN classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pytesseract\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create synthetic text images\n",
        "def create_text_image(text, width=200, height=50, font_size=30):\n",
        "    img = Image.new('RGB', (width, height), 'white')\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
        "    except:\n",
        "        font = ImageFont.load_default()\n",
        "    bbox = draw.textbbox((0, 0), text, font=font)\n",
        "    x = (width - (bbox[2] - bbox[0])) // 2\n",
        "    y = (height - (bbox[3] - bbox[1])) // 2\n",
        "    draw.text((x, y), text, fill='black', font=font)\n",
        "    return img\n",
        "\n",
        "# Generate dataset\n",
        "text_categories = {\n",
        "    'numbers': ['123', '456', '789', '012', '345'],\n",
        "    'letters': ['ABC', 'DEF', 'GHI', 'JKL', 'MNO'],\n",
        "    'words': ['HELLO', 'WORLD', 'TEXT', 'IMAGE', 'OCR'],\n",
        "    'mixed': ['A1B2', 'C3D4', 'E5F6', 'G7H8', 'I9J0']\n",
        "}\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "for category, text_list in text_categories.items():\n",
        "    for text in text_list:\n",
        "        img = create_text_image(text)\n",
        "        images.append(np.array(img))\n",
        "        labels.append(category)\n",
        "\n",
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "print(f\"Dataset: {X.shape}, Labels: {len(labels)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess with OpenCV\n",
        "def preprocess_image(image, target_size=(128, 128)):\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        gray = image.copy()\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    _, thresh = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "    resized = cv2.resize(cleaned, target_size)\n",
        "    normalized = resized.astype('float32') / 255.0\n",
        "    return normalized\n",
        "\n",
        "X_processed = np.array([preprocess_image(img) for img in X])\n",
        "print(f\"Processed shape: {X_processed.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract text with Tesseract OCR\n",
        "def extract_text_ocr(image):\n",
        "    img_uint8 = (image * 255).astype(np.uint8)\n",
        "    pil_image = Image.fromarray(img_uint8)\n",
        "    try:\n",
        "        text = pytesseract.image_to_string(pil_image, config='--psm 7 --oem 3').strip()\n",
        "    except:\n",
        "        text = \"\"\n",
        "    return text\n",
        "\n",
        "extracted_texts = [extract_text_ocr(img) for img in X_processed]\n",
        "print(f\"OCR extracted: {len(extracted_texts)} texts\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# Reshape for CNN\n",
        "X_cnn = X_processed.reshape(X_processed.shape[0], X_processed.shape[1], X_processed.shape[2], 1)\n",
        "y_onehot = keras.utils.to_categorical(y_encoded, num_classes)\n",
        "\n",
        "print(f\"CNN input: {X_cnn.shape}, Labels: {y_onehot.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_cnn, y_onehot, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build CNN model\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=16, validation_split=0.2, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train')\n",
        "plt.plot(history.history['val_accuracy'], label='Val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train')\n",
        "plt.plot(history.history['val_loss'], label='Val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.imshow(cm, cmap='Blues')\n",
        "plt.colorbar()\n",
        "plt.xticks(range(len(label_encoder.classes_)), label_encoder.classes_)\n",
        "plt.yticks(range(len(label_encoder.classes_)), label_encoder.classes_)\n",
        "for i in range(len(label_encoder.classes_)):\n",
        "    for j in range(len(label_encoder.classes_)):\n",
        "        plt.text(j, i, cm[i, j], ha='center', va='center', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model\n",
        "model.save('text_identification_model.h5')\n",
        "print(\"Model saved!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
